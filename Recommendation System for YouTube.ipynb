{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with NLP's Lemma names to find the synonyms of the word 'funny' - one mining try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[[u'funny_story', u'good_story', u'funny_remark', u'funny'], [u'amusing', u'comic', u'comical', u'funny', u'laughable', u'mirthful', u'risible'], [u'curious', u'funny', u'odd', u'peculiar', u'queer', u'rum', u'rummy', u'singular'], [u'fishy', u'funny', u'shady', u'suspect', u'suspicious'], [u'funny']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "print(\"start\")\n",
    "listnames = []\n",
    "\n",
    "for i,j in enumerate(wn.synsets('funny')):\n",
    "    listnames.append(j.lemma_names())\n",
    "print (listnames) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference based on the above NLP library \n",
    "Since the synonyms seem to be irrelevant in some of the above cases like rummy, singular. So it is fine to manually find few word related to the word 'funny' and mine YouTube based on those search keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining dataset from YouTube\n",
    "\n",
    "First, run the youtubeMiner.py script in your console to get the dataset in comma separated values(CSV) format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Curating dataset by removing redundancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>v_id</th>\n",
       "      <th>v_title</th>\n",
       "      <th>viewCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>954</td>\n",
       "      <td>cGKEVtGYr3A</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: DeStorm Power Vines ...</td>\n",
       "      <td>140473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63743</td>\n",
       "      <td>6020</td>\n",
       "      <td>0</td>\n",
       "      <td>363572</td>\n",
       "      <td>aO4dTgt47No</td>\n",
       "      <td>Try Not To Laugh Challenge #4</td>\n",
       "      <td>10085850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>858</td>\n",
       "      <td>1705</td>\n",
       "      <td>0</td>\n",
       "      <td>6999</td>\n",
       "      <td>2B8TjgWgBGg</td>\n",
       "      <td>IMPOSSIBLE NOT TO LAUGH - Funny school fail co...</td>\n",
       "      <td>2315183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>545</td>\n",
       "      <td>1247</td>\n",
       "      <td>0</td>\n",
       "      <td>1341</td>\n",
       "      <td>PQ94T4WAea0</td>\n",
       "      <td>IF YOU LAUGH, YOU LOSE (87% FAIL)</td>\n",
       "      <td>85006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>49203</td>\n",
       "      <td>47778</td>\n",
       "      <td>0</td>\n",
       "      <td>163214</td>\n",
       "      <td>_i4qBHd0FJo</td>\n",
       "      <td>*I BET  MY KIDNEY YOU WILL LAUGH**</td>\n",
       "      <td>12079480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 commentCount dislikeCount favoriteCount likeCount         v_id  \\\n",
       "0         0.0           87          155             0       954  cGKEVtGYr3A   \n",
       "1         1.0        63743         6020             0    363572  aO4dTgt47No   \n",
       "2         2.0          858         1705             0      6999  2B8TjgWgBGg   \n",
       "3         3.0          545         1247             0      1341  PQ94T4WAea0   \n",
       "4         4.0        49203        47778             0    163214  _i4qBHd0FJo   \n",
       "\n",
       "                                             v_title viewCount  \n",
       "0  TRY NOT TO LAUGH or GRIN: DeStorm Power Vines ...    140473  \n",
       "1                      Try Not To Laugh Challenge #4  10085850  \n",
       "2  IMPOSSIBLE NOT TO LAUGH - Funny school fail co...   2315183  \n",
       "3                  IF YOU LAUGH, YOU LOSE (87% FAIL)     85006  \n",
       "4                 *I BET  MY KIDNEY YOU WILL LAUGH**  12079480  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('YTlaughable123.csv', encoding='utf-8')\n",
    "\n",
    "df1 = df.drop_duplicates(['v_title'])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### Why not a recommendation based on the number of views and likes ? \n",
    "\n",
    "I have collected the videos along with their view count, number of likes and dislikes in the csv file which mined the YouTube. Based on the above information, it becomes easy to recommend videos based on number of likes and views of the videos just by sorting. But pernolization comes into question with this model of recommendation. So I am planning to introduce some assumptions inorder to make this recommendation system work more personalized.\n",
    "\n",
    "\n",
    "### Assumptions \n",
    "\n",
    "Introducing 6 users in the dataset and whose names are Kathir, Sundhar, Chris, Patrick, MSD and MarkZ in \"Users\". Along with those users, I have also introduced the assumed like count of each video to that paticular user. This may seem to be little fuzzy. But it is like normal mapping of one user to the multiple videos in the dataset and each video will have the like or dislike option in the \"Liked\" column. If the value is 1, then that user liked that video. If the value is 0, then it can be considered as dislike or not watched that video.\n",
    "\n",
    "\n",
    "### Collaborative Filtering\n",
    "\n",
    "In order to implement the recommendation system with personlization, collaborative filtering comes into light. Many companies like MovieLens, Netflix, YouTube etc. are using collaborative filtering in their movies and videos recommendation systems. Collaborative filtering has two different types.\n",
    "1. Model based collaborative filtering \n",
    "2. Memory based collaborative filtering\n",
    "\n",
    "I am using memory based collaborative filtering in this project. Again collaborative filtering has its subtypes. They are item-item filtering and user-user filtering. In particular, I have implemented the recommendation system using item-item filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection based on the above assumption\n",
    "\n",
    "For the following project, I need only around 300 unique videos. But I have sampled around 700 videos with multiple users and their choices.\n",
    "\n",
    "The above mined csv file is changed into users5times100Videos.csv with the mentioned assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>v_title</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>10 PRANK SERU YG GAMPANG DILAKUKAN DI RUMAH TA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>MSD</td>\n",
       "      <td>You laugh you lose #17 - Try not to laugh chal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>WE GOT JAKE PAUL ARRESTED! *PRANK WARS*</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>Try to Watch This Without Laughing or Grinning...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Try Not To Laugh - Funny Animals Compilation 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>MSD</td>\n",
       "      <td>TYVERI PRANK PÃ… KRISTIAN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: Funny Fails Vines Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>MSD</td>\n",
       "      <td>Try Not To Laugh or Grin: Funny Vines Compilat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>MSD</td>\n",
       "      <td>DROPPING $100,000 PRANK!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>MSD</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: Funny Pranks Vines C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Bait Backpack Prank</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>BREAKING UP WITH MY GIRLFRIEND *PRANK* GONE WRONG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN Funny Animals Doing S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>THE BOSS BABY Craziness #1 | TRY TO LAUGH | Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Try Not To Laugh or Grin While Watching Funny ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>Bait Backpack Prank</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>FUNNY VIDEOS that will make you LAUGH INSANELY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: DeStorm Power Vines ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Chris</td>\n",
       "      <td>SHAMPOO PRANK PART 9! | HoomanTV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>DJANI LYRICS PRANK NA MOJOJ BIVSOJ DJEVOJCI !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>ITCHING BAIT PHONE PRANK!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>MSD</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: Funny Fails Vines Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>1 MILLION ORBEEZ IN GIRLFRIEND'S CAR PRANK!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Asian Nintendo Switch Addiction Prank</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>Best Prank Vines Compilation | Top Pranks Vine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Chris</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: Funny Kids Fails Com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>Try Not To Laugh or Grin - Funny Kids Fails Vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>MSD</td>\n",
       "      <td>FUNNY PRANKS!! ROOMMATE WARS!! Alisha Marie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>FIDGET SPINNER IN HAPPY MEAL PRANK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>Wanna LAUGH LIKE HELL, WATCH THIS! - Super FUN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>SHAMPOO PRANK PART 7! | HoomanTV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Wanna LAUGH LIKE HELL, WATCH THIS! - Super FUN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Chris</td>\n",
       "      <td>SLIME PRANK ON BROTHERS CAR!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>MSD</td>\n",
       "      <td>FIDGET SPINNER IN HAPPY MEAL PRANK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>MSD</td>\n",
       "      <td>TRY NOT TO LAUGH Funny Animals Vines Compilati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>MSD</td>\n",
       "      <td>BLINDFOLD PRANK ON MY GIRLFRIEND</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>Try Not To Laugh Funny Animals Vines - Best Vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Chris</td>\n",
       "      <td>SHAMPOO PRANK PART 7! | HoomanTV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Chris</td>\n",
       "      <td>*IMPOSSIBLE CHALLENGE* Try Not to Laugh or Gri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>10 PRANK SERU YG GAMPANG DILAKUKAN DI RUMAH TA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>Try Not To Laugh - Funny Animals Compilation 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: Funny Pranks Vines C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN Funny Animals Doing S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>MSD</td>\n",
       "      <td>Break Up PRANK turns into PROPOSAL! GONE WRONG!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>Try Not To Laugh - Funny Animals Compilation 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>Epic Prank Compilation: Parents Prank Kids</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>*I BET  MY KIDNEY YOU WILL LAUGH**</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>If you don't laugh, you have no soul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Chris</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: Funny Fails Compilat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Sundhar</td>\n",
       "      <td>we got KICKED OUT of our home! (PRANK WARS)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: Funny Fails Vines Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>SLIME PRANK ON BROTHERS CAR!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>You laugh you lose #17 - Try not to laugh chal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>Try Not To Laugh Challenge #4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN Funny Animals Doing S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>Try Not To Laugh - Funny Animals Compilation 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Kathir</td>\n",
       "      <td>Bought Fake Louis Vuitton Prank/Gold Digger Test!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>MOR FORELSKET I ALBERT! (PRANK)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>Asian Nintendo Switch Addiction Prank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>MarkZ</td>\n",
       "      <td>TYVERI PRANK PÃ… KRISTIAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       users                                            v_title  Liked\n",
       "493  Patrick  10 PRANK SERU YG GAMPANG DILAKUKAN DI RUMAH TA...      1\n",
       "218      MSD  You laugh you lose #17 - Try not to laugh chal...      0\n",
       "466  Patrick            WE GOT JAKE PAUL ARRESTED! *PRANK WARS*      0\n",
       "147  Sundhar  Try to Watch This Without Laughing or Grinning...      0\n",
       "323    Chris  Try Not To Laugh - Funny Animals Compilation 2...      0\n",
       "292      MSD                           TYVERI PRANK PÃ… KRISTIAN      1\n",
       "118  Sundhar  TRY NOT TO LAUGH or GRIN: Funny Fails Vines Co...      0\n",
       "245      MSD  Try Not To Laugh or Grin: Funny Vines Compilat...      1\n",
       "257      MSD                          DROPPING $100,000 PRANK!!      0\n",
       "203      MSD  TRY NOT TO LAUGH or GRIN: Funny Pranks Vines C...      0\n",
       "368    Chris                                Bait Backpack Prank      0\n",
       "61    Kathir  BREAKING UP WITH MY GIRLFRIEND *PRANK* GONE WRONG      0\n",
       "143  Sundhar  TRY NOT TO LAUGH or GRIN Funny Animals Doing S...      0\n",
       "518    MarkZ  THE BOSS BABY Craziness #1 | TRY TO LAUGH | Th...      1\n",
       "307    Chris  Try Not To Laugh or Grin While Watching Funny ...      0\n",
       "467  Patrick                                Bait Backpack Prank      0\n",
       "107  Sundhar  FUNNY VIDEOS that will make you LAUGH INSANELY...      0\n",
       "0     Kathir  TRY NOT TO LAUGH or GRIN: DeStorm Power Vines ...      1\n",
       "383    Chris                   SHAMPOO PRANK PART 9! | HoomanTV      1\n",
       "190  Sundhar      DJANI LYRICS PRANK NA MOJOJ BIVSOJ DJEVOJCI !      1\n",
       "58    Kathir                         ITCHING BAIT PHONE PRANK!!      0\n",
       "224      MSD  TRY NOT TO LAUGH or GRIN: Funny Fails Vines Co...      0\n",
       "586    MarkZ        1 MILLION ORBEEZ IN GIRLFRIEND'S CAR PRANK!      0\n",
       "359    Chris              Asian Nintendo Switch Addiction Prank      0\n",
       "193  Sundhar  Best Prank Vines Compilation | Top Pranks Vine...      1\n",
       "303    Chris  TRY NOT TO LAUGH or GRIN: Funny Kids Fails Com...      0\n",
       "427  Patrick  Try Not To Laugh or Grin - Funny Kids Fails Vi...      0\n",
       "274      MSD        FUNNY PRANKS!! ROOMMATE WARS!! Alisha Marie      0\n",
       "192  Sundhar                 FIDGET SPINNER IN HAPPY MEAL PRANK      1\n",
       "408  Patrick  Wanna LAUGH LIKE HELL, WATCH THIS! - Super FUN...      0\n",
       "..       ...                                                ...    ...\n",
       "461  Patrick                   SHAMPOO PRANK PART 7! | HoomanTV      1\n",
       "309    Chris  Wanna LAUGH LIKE HELL, WATCH THIS! - Super FUN...      0\n",
       "379    Chris                       SLIME PRANK ON BROTHERS CAR!      1\n",
       "290      MSD                 FIDGET SPINNER IN HAPPY MEAL PRANK      1\n",
       "239      MSD  TRY NOT TO LAUGH Funny Animals Vines Compilati...      1\n",
       "265      MSD                   BLINDFOLD PRANK ON MY GIRLFRIEND      0\n",
       "35    Kathir  Try Not To Laugh Funny Animals Vines - Best Vi...      0\n",
       "362    Chris                   SHAMPOO PRANK PART 7! | HoomanTV      0\n",
       "324    Chris  *IMPOSSIBLE CHALLENGE* Try Not to Laugh or Gri...      0\n",
       "197  Sundhar  10 PRANK SERU YG GAMPANG DILAKUKAN DI RUMAH TA...      1\n",
       "126  Sundhar  Try Not To Laugh - Funny Animals Compilation 2...      0\n",
       "400  Patrick  TRY NOT TO LAUGH or GRIN: Funny Pranks Vines C...      1\n",
       "439  Patrick  TRY NOT TO LAUGH or GRIN Funny Animals Doing S...      1\n",
       "256      MSD    Break Up PRANK turns into PROPOSAL! GONE WRONG!      1\n",
       "422  Patrick  Try Not To Laugh - Funny Animals Compilation 2...      0\n",
       "591    MarkZ         Epic Prank Compilation: Parents Prank Kids      0\n",
       "399  Patrick                 *I BET  MY KIDNEY YOU WILL LAUGH**      1\n",
       "135  Sundhar            If you don't laugh, you have no soul...      0\n",
       "329    Chris  TRY NOT TO LAUGH or GRIN: Funny Fails Compilat...      1\n",
       "180  Sundhar        we got KICKED OUT of our home! (PRANK WARS)      1\n",
       "26    Kathir  TRY NOT TO LAUGH or GRIN: Funny Fails Vines Co...      0\n",
       "83    Kathir                       SLIME PRANK ON BROTHERS CAR!      1\n",
       "514    MarkZ  You laugh you lose #17 - Try not to laugh chal...      1\n",
       "495    MarkZ                      Try Not To Laugh Challenge #4      1\n",
       "538    MarkZ  TRY NOT TO LAUGH or GRIN Funny Animals Doing S...      1\n",
       "27    Kathir  Try Not To Laugh - Funny Animals Compilation 2...      0\n",
       "84    Kathir  Bought Fake Louis Vuitton Prank/Gold Digger Test!      1\n",
       "574    MarkZ                    MOR FORELSKET I ALBERT! (PRANK)      0\n",
       "458  Patrick              Asian Nintendo Switch Addiction Prank      1\n",
       "589    MarkZ                           TYVERI PRANK PÃ… KRISTIAN      0\n",
       "\n",
       "[593 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import graphlab # Need to register for this library but it comes for free to university students \n",
    "\"\"\"\n",
    "graphlab : \n",
    "==========\n",
    "Need to register online for using this library else it will throw an error saying that the product is not registered. \n",
    "\n",
    "Please refer to the following link for further instructions.\n",
    "https://turi.com/download/install-graphlab-create-command-line.html\n",
    "\n",
    "\"\"\"\n",
    "newdf = pd.read_csv('users5times100Videos.csv', encoding='utf-8')\n",
    "from sklearn.utils import shuffle\n",
    "newdf = shuffle(newdf) #Shuffling the dataset in order to randomize the data\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\hp\\AppData\\Local\\Temp\\graphlab_server_1588766779.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to ameyp.sunu2017@vitstudent.ac.in and will expire on March 18, 2021.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = popularity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = popularity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 251 observations with 6 users and 95 items.</pre>"
      ],
      "text/plain": [
       "    Data has 251 observations with 6 users and 95 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.001541s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.001541s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>251 observations to process; with 95 unique items.</pre>"
      ],
      "text/plain": [
       "251 observations to process; with 95 unique items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = newdf.ix[:250,:]\n",
    "test = newdf.ix[250:,:]\n",
    "train_data = graphlab.SFrame(train)\n",
    "test_data = graphlab.SFrame(test)\n",
    "popularity_model = graphlab.popularity_recommender.create(train_data, user_id='users', item_id='v_title', target='Liked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------+----------------+------+\n",
      "| users |            v_title            |     score      | rank |\n",
      "+-------+-------------------------------+----------------+------+\n",
      "|  MSD  | Bought Fake Louis Vuitton ... |      1.0       |  1   |\n",
      "|  MSD  |  SLIME PRANK ON BROTHERS CAR! |      1.0       |  2   |\n",
      "|  MSD  | Killer Clown 9 Scare Prank... |      1.0       |  3   |\n",
      "|  MSD  | we got KICKED OUT of our h... |      1.0       |  4   |\n",
      "|  MSD  | MOR FORELSKET I ALBERT! (P... |      1.0       |  5   |\n",
      "|  MSD  | PIZZA DELIVERY PRANK ON MY... |      1.0       |  6   |\n",
      "|  MSD  | Headless man Prank part 2 ... |      1.0       |  7   |\n",
      "|  MSD  | ðŸ‘‘ Tying Peoples Shoes and... |      0.5       |  8   |\n",
      "|  MSD  | GOLD DIGGER PRANK PART 2! ... |      0.5       |  9   |\n",
      "|  MSD  | Old Man Street Workout Pra... |      0.5       |  10  |\n",
      "| MarkZ | Bought Fake Louis Vuitton ... |      1.0       |  1   |\n",
      "| MarkZ |  SLIME PRANK ON BROTHERS CAR! |      1.0       |  2   |\n",
      "| MarkZ | Killer Clown 9 Scare Prank... |      1.0       |  3   |\n",
      "| MarkZ | we got KICKED OUT of our h... |      1.0       |  4   |\n",
      "| MarkZ | MOR FORELSKET I ALBERT! (P... |      1.0       |  5   |\n",
      "| MarkZ | PIZZA DELIVERY PRANK ON MY... |      1.0       |  6   |\n",
      "| MarkZ | Headless man Prank part 2 ... |      1.0       |  7   |\n",
      "| MarkZ | TRY NOT TO LAUGH Funny Ani... | 0.666666666667 |  8   |\n",
      "| MarkZ | Try Not To Laugh or Grin -... | 0.666666666667 |  9   |\n",
      "| MarkZ | TRY NOT TO LAUGH or GRIN: ... | 0.666666666667 |  10  |\n",
      "| Chris | Bought Fake Louis Vuitton ... |      1.0       |  1   |\n",
      "| Chris |  SLIME PRANK ON BROTHERS CAR! |      1.0       |  2   |\n",
      "| Chris | Killer Clown 9 Scare Prank... |      1.0       |  3   |\n",
      "| Chris | we got KICKED OUT of our h... |      1.0       |  4   |\n",
      "| Chris | MOR FORELSKET I ALBERT! (P... |      1.0       |  5   |\n",
      "+-------+-------------------------------+----------------+------+\n",
      "[40 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get recommendations for first 5 users and print them\n",
    "#users = range(1,6) specifies user ID of first 5 users\n",
    "#k=5 specifies top 5 recommendations to be given\n",
    "user_names = ['Kathir','MSD','MarkZ','Chris','Sundhar','Patrick']\n",
    "popularity_recomm = popularity_model.recommend(users=user_names,k=10)\n",
    "popularity_recomm.print_rows(num_rows=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v_title\n",
       "SLIME PRANK ON BROTHERS CAR!                                                                            1.000000\n",
       "we got KICKED OUT of our home! (PRANK WARS)                                                             1.000000\n",
       "PIZZA DELIVERY PRANK ON MY GIRLFRIEND'S STALKER (GONE WRONG!!!)                                         1.000000\n",
       "Headless man Prank part 2 (slaughter version)- Julien magic                                             1.000000\n",
       "Bought Fake Louis Vuitton Prank/Gold Digger Test!                                                       1.000000\n",
       "MOR FORELSKET I ALBERT! (PRANK)                                                                         1.000000\n",
       "Killer Clown 9 Scare Prank - Shadow Plays                                                               1.000000\n",
       "TRY NOT TO LAUGH or GRIN: DeStorm Power Vines - Funny Vines Compilation 2017 | Life Awesome             0.666667\n",
       "HARDEST VERSION AFV Try Not to Laugh or Grin While Watching Funniest Vines of best funny videos 2017    0.666667\n",
       "TRY NOT TO LAUGH or GRIN: Funny Fails Compilation 2017 - Top 100 Funny Fails Vines Video Ever           0.666667\n",
       "TRY NOT TO LAUGH or GRIN: Funny Animals Vines Compilation 2017 | Funny Animals and Kids Fails Vines     0.666667\n",
       "IMPOSSIBLE NOT TO LAUGH - Funny school fail compilation                                                 0.666667\n",
       "TRY NOT TO LAUGH or GRIN Funny Animals Doing Stupid Things #2 | Funny Animals Vines Compilation 2017    0.666667\n",
       "GIANT WUBBLE BUBBLE CAR PRANK!                                                                          0.666667\n",
       "TRY NOT TO LAUGH or GRIN - Funny Fails Compilation 2017                                                 0.666667\n",
       "TRY NOT TO LAUGH Funny Animals Vines Compilation - Best Funny Videos of Animals Doing Stupid Things     0.666667\n",
       "TRY NOT TO LAUGH (IMPOSSIBLE CHALLENGE) PART 2                                                          0.666667\n",
       "THE BEST PRANK OF ALL TIME!!!                                                                           0.666667\n",
       "TRY NOT TO LAUGH or GRIN: Funny Kids Fails Compilation 2017 | Best Kids Fails Vines of May 2017         0.666667\n",
       "*I BET  MY KIDNEY YOU WILL LAUGH**                                                                      0.666667\n",
       "Name: Liked, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by='v_title')['Liked'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering implemented using graphlab\n",
    "\n",
    "Reminder : Need to register graphlab package inorder to use it but it comes for free\n",
    "\n",
    "I am implementing this recommendation system by making an item-item matrix in which we keep a record of the pair of items which were liked together.\n",
    "\n",
    "In this case, an item is a YouTube video. Once I have the matrix, I use it to determine the best recommendations for a user based on the videos he has already liked. Note that there a few more things to take care in actual implementation which would require deeper mathematical introspection, which Iâ€™ll skip for now.\n",
    "\n",
    "Three types of item similarity metrics supported by graphlab are \n",
    "\n",
    "#### 1. Jaccard Similarity: \n",
    "Similarity is based on the number of users which have rated item A and B divided by the number of users who have rated either A or B. It is typically used where we donâ€™t have a numeric rating but just a boolean value like a product being bought or an add being clicked\n",
    "\n",
    "#### 2. Pearson Similarity\n",
    "Similarity is the pearson coefficient between the two vectors\n",
    "\n",
    "#### 3. Cosine Similarity:\n",
    "Similarity is the cosine of the angle between the 2 vectors of the item vectors of A and B. Closer the vectors, smaller will be the angle and larger the cosine\n",
    "\n",
    "For detailed explanation on the cosine similarity and other similar methods, Please check the following links : \n",
    "\n",
    "https://turi.com/products/create/docs/generated/graphlab.recommender.item_similarity_recommender.ItemSimilarityRecommender.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 251 observations with 6 users and 95 items.</pre>"
      ],
      "text/plain": [
       "    Data has 251 observations with 6 users and 95 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.003988s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.003988s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Training model from provided data.</pre>"
      ],
      "text/plain": [
       "Training model from provided data."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Gathering per-item and per-user statistics.</pre>"
      ],
      "text/plain": [
       "Gathering per-item and per-user statistics."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Item Statistics) | % Complete |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Item Statistics) | % Complete |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 0us                            | 100        |</pre>"
      ],
      "text/plain": [
       "| 0us                            | 100        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Setting up lookup tables.</pre>"
      ],
      "text/plain": [
       "Setting up lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Processing data in one pass using dense lookup tables.</pre>"
      ],
      "text/plain": [
       "Processing data in one pass using dense lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 871us                               | 11.5             | 11              |</pre>"
      ],
      "text/plain": [
       "| 871us                               | 11.5             | 11              |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1.867ms                             | 100              | 95              |</pre>"
      ],
      "text/plain": [
       "| 1.867ms                             | 100              | 95              |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finalizing lookup tables.</pre>"
      ],
      "text/plain": [
       "Finalizing lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Generating candidate set for working with new users.</pre>"
      ],
      "text/plain": [
       "Generating candidate set for working with new users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished training in 1.00312s</pre>"
      ],
      "text/plain": [
       "Finished training in 1.00312s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b5fd571484e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Make Recommendations:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mitem_sim_recomm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_sim_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mitem_sim_recomm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_names' is not defined"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "item_sim_model = graphlab.item_similarity_recommender.create(train_data, user_id='users', item_id='v_title', target='Liked', similarity_type='cosine')\n",
    "\n",
    "#Make Recommendations:\n",
    "item_sim_recomm = item_sim_model.recommend(users=user_names,k=10)\n",
    "item_sim_recomm.print_rows(num_rows=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics for this Recommendation System \n",
    "\n",
    "#### 1. Recall\n",
    "What ratio of items that a user likes were actually recommended.\n",
    "If a user likes say 5 items and the recommendation decided to show 3 of them, then the recall is 0.6\n",
    "\n",
    "#### 2. Precision\n",
    "Out of all the recommended items, how many the user actually liked?\n",
    "If 5 items were recommended to the user out of which he liked say 4 of them, then precision is 0.8\n",
    "\n",
    "For further information for Recall and Precision, Please refer the following link : \n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Evaluate model M0\n",
      "\n",
      "Precision and recall summary statistics by cutoff\n",
      "+--------+----------------+-----------------+\n",
      "| cutoff | mean_precision |   mean_recall   |\n",
      "+--------+----------------+-----------------+\n",
      "|   1    | 0.666666666667 | 0.0116590485664 |\n",
      "|   2    | 0.833333333333 |  0.029274243032 |\n",
      "|   3    | 0.888888888889 | 0.0468894374976 |\n",
      "|   4    | 0.916666666667 | 0.0645046319632 |\n",
      "|   5    | 0.933333333333 | 0.0821198264288 |\n",
      "|   6    | 0.944444444444 | 0.0997350208944 |\n",
      "|   7    | 0.952380952381 |  0.11735021536  |\n",
      "|   8    | 0.958333333333 |  0.134965409826 |\n",
      "|   9    | 0.962962962963 |  0.152580604291 |\n",
      "|   10   | 0.966666666667 |  0.170195798757 |\n",
      "+--------+----------------+-----------------+\n",
      "[10 rows x 3 columns]\n",
      "\n",
      "PROGRESS: Evaluate model M1\n",
      "\n",
      "Precision and recall summary statistics by cutoff\n",
      "+--------+----------------+-----------------+\n",
      "| cutoff | mean_precision |   mean_recall   |\n",
      "+--------+----------------+-----------------+\n",
      "|   1    |      1.0       | 0.0176151944656 |\n",
      "|   2    |      1.0       | 0.0352303889312 |\n",
      "|   3    |      1.0       | 0.0528455833968 |\n",
      "|   4    |      1.0       | 0.0704607778624 |\n",
      "|   5    |      1.0       |  0.088075972328 |\n",
      "|   6    |      1.0       |  0.105691166794 |\n",
      "|   7    | 0.97619047619  |  0.120618189216 |\n",
      "|   8    | 0.979166666667 |  0.138233383682 |\n",
      "|   9    | 0.981481481481 |  0.155848578147 |\n",
      "|   10   | 0.983333333333 |  0.173463772613 |\n",
      "+--------+----------------+-----------------+\n",
      "[10 rows x 3 columns]\n",
      "\n",
      "Model compare metric: precision_recall\n",
      "Canvas is accessible via web browser at the URL: http://localhost:58589/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "model_performance = graphlab.compare(test_data, [popularity_model, item_sim_model])\n",
    "graphlab.show_comparison(model_performance,[popularity_model, item_sim_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
